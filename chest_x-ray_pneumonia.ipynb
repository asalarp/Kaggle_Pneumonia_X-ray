{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chest_xray_pneumonia.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbrrqfmFoSRp",
        "outputId": "37cf1fc5-1429-4723-e48e-29d55ab6328b"
      },
      "source": [
        "# mounting google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzicW5fkp9LO"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h375W7Plkcp6"
      },
      "source": [
        "# Data loading and preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFkqv8WuqK94"
      },
      "source": [
        "train_dir = \"/content/drive/MyDrive/ML Project/Pneumonia//train\"\n",
        "valid_dir = \"/content/drive/MyDrive/ML Project/Pneumonia/valid\"\n",
        "test_dir = \"/content/drive/MyDrive/ML Project/Pneumonia/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ztIg-PxqO6z",
        "outputId": "8410980b-868c-4a36-f2a7-019f9c14807a"
      },
      "source": [
        "batch_size=28\n",
        "target_size=(150,150)\n",
        "rescale=1./255.\n",
        "zoom_range=0.3\n",
        "vertical_flip=True\n",
        "\n",
        "train_datagen=ImageDataGenerator(rescale=rescale,zoom_range=zoom_range ,vertical_flip=vertical_flip)\n",
        "test_datagen=ImageDataGenerator(rescale=rescale)\n",
        "valid_datagen=ImageDataGenerator(rescale=rescale)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,target_size=target_size,batch_size=batch_size,class_mode=\"binary\")\n",
        "valid_generator = valid_datagen.flow_from_directory(valid_dir,target_size=target_size,batch_size=batch_size,class_mode=\"binary\")\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,target_size=target_size,batch_size=batch_size,class_mode=\"binary\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL7DlBk-kmos"
      },
      "source": [
        "# Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqqbjxToqRUP"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (5, 5), activation='relu',padding='same',\n",
        "                    input_shape=(150, 150, 3)))\n",
        "model.add(layers.Conv2D(64, (5,5), activation='relu',padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu',padding='same',kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu',padding='same',kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(512, (3, 3), activation='relu',padding='same',kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.0005),loss='binary_crossentropy',metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUIwaGCE7v4P",
        "outputId": "988be220-4b78-4170-86d0-58cbf156ab1c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 150, 150, 32)      2432      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 150, 150, 64)      51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 75, 75, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 18, 18, 512)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 41472)             0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 41472)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 41473     \n",
            "=================================================================\n",
            "Total params: 1,644,353\n",
            "Trainable params: 1,644,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-KbbHzmk6dZ"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcSQMf6uqXOR",
        "outputId": "c364f708-8a68-4297-a8a0-1f93d087db05"
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath,monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto')\n",
        "history = model.fit(train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=epochs,\n",
        "                    validation_data=valid_generator, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "186/186 [==============================] - 4164s 22s/step - loss: 0.9165 - accuracy: 0.7161 - val_loss: 0.8397 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.83973, saving model to weights-improvement.hdf5\n",
            "Epoch 2/50\n",
            "186/186 [==============================] - 102s 549ms/step - loss: 0.4702 - accuracy: 0.8032 - val_loss: 0.7364 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.83973 to 0.73636, saving model to weights-improvement.hdf5\n",
            "Epoch 3/50\n",
            "186/186 [==============================] - 102s 545ms/step - loss: 0.3562 - accuracy: 0.8549 - val_loss: 0.5430 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.73636 to 0.54302, saving model to weights-improvement.hdf5\n",
            "Epoch 4/50\n",
            "186/186 [==============================] - 101s 542ms/step - loss: 0.3228 - accuracy: 0.8812 - val_loss: 0.5417 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.54302 to 0.54171, saving model to weights-improvement.hdf5\n",
            "Epoch 5/50\n",
            "186/186 [==============================] - 101s 543ms/step - loss: 0.2643 - accuracy: 0.9052 - val_loss: 0.6616 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.54171\n",
            "Epoch 6/50\n",
            "186/186 [==============================] - 101s 545ms/step - loss: 0.2634 - accuracy: 0.9062 - val_loss: 0.7541 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.54171\n",
            "Epoch 7/50\n",
            "186/186 [==============================] - 101s 546ms/step - loss: 0.2631 - accuracy: 0.9059 - val_loss: 0.5798 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.54171\n",
            "Epoch 8/50\n",
            "186/186 [==============================] - 102s 547ms/step - loss: 0.2463 - accuracy: 0.9111 - val_loss: 0.4225 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.54171 to 0.42250, saving model to weights-improvement.hdf5\n",
            "Epoch 9/50\n",
            "186/186 [==============================] - 101s 544ms/step - loss: 0.2386 - accuracy: 0.9101 - val_loss: 0.7296 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.42250\n",
            "Epoch 10/50\n",
            "186/186 [==============================] - 101s 542ms/step - loss: 0.2289 - accuracy: 0.9116 - val_loss: 0.8844 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.42250\n",
            "Epoch 11/50\n",
            "186/186 [==============================] - 101s 543ms/step - loss: 0.2183 - accuracy: 0.9187 - val_loss: 0.6083 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.42250\n",
            "Epoch 12/50\n",
            "186/186 [==============================] - 102s 549ms/step - loss: 0.1923 - accuracy: 0.9290 - val_loss: 0.4720 - val_accuracy: 0.9375\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.42250\n",
            "Epoch 13/50\n",
            "186/186 [==============================] - 102s 546ms/step - loss: 0.2292 - accuracy: 0.9224 - val_loss: 0.7816 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.42250\n",
            "Epoch 14/50\n",
            "186/186 [==============================] - 101s 544ms/step - loss: 0.2031 - accuracy: 0.9323 - val_loss: 1.2728 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.42250\n",
            "Epoch 15/50\n",
            "186/186 [==============================] - 101s 541ms/step - loss: 0.1906 - accuracy: 0.9324 - val_loss: 1.0516 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.42250\n",
            "Epoch 16/50\n",
            "186/186 [==============================] - 100s 539ms/step - loss: 0.1966 - accuracy: 0.9244 - val_loss: 1.0731 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.42250\n",
            "Epoch 17/50\n",
            "186/186 [==============================] - 101s 541ms/step - loss: 0.1734 - accuracy: 0.9409 - val_loss: 0.5745 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.42250\n",
            "Epoch 18/50\n",
            "186/186 [==============================] - 101s 542ms/step - loss: 0.1785 - accuracy: 0.9365 - val_loss: 1.5447 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.42250\n",
            "Epoch 19/50\n",
            "186/186 [==============================] - 101s 541ms/step - loss: 0.1936 - accuracy: 0.9335 - val_loss: 1.0189 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.42250\n",
            "Epoch 20/50\n",
            "186/186 [==============================] - 101s 544ms/step - loss: 0.1742 - accuracy: 0.9367 - val_loss: 0.8117 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.42250\n",
            "Epoch 21/50\n",
            "186/186 [==============================] - 101s 540ms/step - loss: 0.1768 - accuracy: 0.9401 - val_loss: 1.2809 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.42250\n",
            "Epoch 22/50\n",
            "186/186 [==============================] - 101s 542ms/step - loss: 0.1845 - accuracy: 0.9380 - val_loss: 1.1858 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.42250\n",
            "Epoch 23/50\n",
            "186/186 [==============================] - 101s 542ms/step - loss: 0.1567 - accuracy: 0.9473 - val_loss: 1.2074 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.42250\n",
            "Epoch 24/50\n",
            "186/186 [==============================] - 100s 536ms/step - loss: 0.1792 - accuracy: 0.9385 - val_loss: 0.8515 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.42250\n",
            "Epoch 25/50\n",
            "186/186 [==============================] - 100s 536ms/step - loss: 0.1594 - accuracy: 0.9478 - val_loss: 0.8879 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.42250\n",
            "Epoch 26/50\n",
            "186/186 [==============================] - 102s 548ms/step - loss: 0.1567 - accuracy: 0.9460 - val_loss: 0.9336 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.42250\n",
            "Epoch 27/50\n",
            "186/186 [==============================] - 103s 551ms/step - loss: 0.1590 - accuracy: 0.9463 - val_loss: 0.6032 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.42250\n",
            "Epoch 28/50\n",
            "186/186 [==============================] - 101s 542ms/step - loss: 0.1520 - accuracy: 0.9458 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.42250\n",
            "Epoch 29/50\n",
            "186/186 [==============================] - 101s 540ms/step - loss: 0.1508 - accuracy: 0.9498 - val_loss: 1.4112 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.42250\n",
            "Epoch 30/50\n",
            "186/186 [==============================] - 101s 545ms/step - loss: 0.1658 - accuracy: 0.9441 - val_loss: 1.3874 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.42250\n",
            "Epoch 31/50\n",
            "186/186 [==============================] - 101s 543ms/step - loss: 0.1549 - accuracy: 0.9461 - val_loss: 1.2118 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.42250\n",
            "Epoch 32/50\n",
            "186/186 [==============================] - 101s 542ms/step - loss: 0.1648 - accuracy: 0.9458 - val_loss: 0.6767 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.42250\n",
            "Epoch 33/50\n",
            "186/186 [==============================] - 100s 537ms/step - loss: 0.1628 - accuracy: 0.9393 - val_loss: 1.3151 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.42250\n",
            "Epoch 34/50\n",
            "186/186 [==============================] - 101s 540ms/step - loss: 0.1269 - accuracy: 0.9571 - val_loss: 0.5754 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.42250\n",
            "Epoch 35/50\n",
            "186/186 [==============================] - 102s 549ms/step - loss: 0.1459 - accuracy: 0.9544 - val_loss: 1.3423 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.42250\n",
            "Epoch 36/50\n",
            "186/186 [==============================] - 102s 549ms/step - loss: 0.1489 - accuracy: 0.9507 - val_loss: 0.5955 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.42250\n",
            "Epoch 37/50\n",
            "186/186 [==============================] - 102s 547ms/step - loss: 0.1473 - accuracy: 0.9517 - val_loss: 2.0320 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.42250\n",
            "Epoch 38/50\n",
            "186/186 [==============================] - 102s 548ms/step - loss: 0.1381 - accuracy: 0.9560 - val_loss: 0.6704 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.42250\n",
            "Epoch 39/50\n",
            "186/186 [==============================] - 102s 548ms/step - loss: 0.1497 - accuracy: 0.9569 - val_loss: 1.0348 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.42250\n",
            "Epoch 40/50\n",
            "186/186 [==============================] - 103s 551ms/step - loss: 0.1343 - accuracy: 0.9540 - val_loss: 1.0173 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.42250\n",
            "Epoch 41/50\n",
            "186/186 [==============================] - 102s 545ms/step - loss: 0.1406 - accuracy: 0.9538 - val_loss: 2.1927 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.42250\n",
            "Epoch 42/50\n",
            "186/186 [==============================] - 102s 549ms/step - loss: 0.1552 - accuracy: 0.9474 - val_loss: 0.3384 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.42250 to 0.33838, saving model to weights-improvement.hdf5\n",
            "Epoch 43/50\n",
            "186/186 [==============================] - 100s 538ms/step - loss: 0.1328 - accuracy: 0.9567 - val_loss: 1.0033 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.33838\n",
            "Epoch 44/50\n",
            "186/186 [==============================] - 100s 538ms/step - loss: 0.1485 - accuracy: 0.9491 - val_loss: 0.7429 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.33838\n",
            "Epoch 45/50\n",
            "186/186 [==============================] - 101s 544ms/step - loss: 0.1258 - accuracy: 0.9528 - val_loss: 0.5995 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.33838\n",
            "Epoch 46/50\n",
            "186/186 [==============================] - 100s 538ms/step - loss: 0.1290 - accuracy: 0.9578 - val_loss: 0.7248 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.33838\n",
            "Epoch 47/50\n",
            "186/186 [==============================] - 100s 540ms/step - loss: 0.1293 - accuracy: 0.9556 - val_loss: 0.7424 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.33838\n",
            "Epoch 48/50\n",
            "186/186 [==============================] - 101s 540ms/step - loss: 0.1323 - accuracy: 0.9592 - val_loss: 0.9460 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.33838\n",
            "Epoch 49/50\n",
            "186/186 [==============================] - 100s 535ms/step - loss: 0.1340 - accuracy: 0.9540 - val_loss: 1.2178 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.33838\n",
            "Epoch 50/50\n",
            "186/186 [==============================] - 100s 538ms/step - loss: 0.1242 - accuracy: 0.9565 - val_loss: 1.0150 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.33838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA1wj6FblOM4"
      },
      "source": [
        "# Loss/Accuracy visualization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "fXS4hZ7VY_c0",
        "outputId": "a9840f3e-5e8e-45d6-decd-e324ea3fcc84"
      },
      "source": [
        "def plot(history,figsize,y,x):\n",
        "    history_dict=history.history\n",
        "    loss=history_dict[y]\n",
        "    acc=history_dict[x]\n",
        "    epoch=range(1,len(acc)+1)\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(epoch,loss,'bo',label='Training loss')\n",
        "    plt.plot(epoch,acc,'r',label='Training accuracy')\n",
        "    plt.xlabel('Epoches')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "plot(train_history,(12,4),y='loss',x='accuracy')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSlozjqb1NYJ"
      },
      "source": [
        "# Test evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJYCttii0pq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780b61e2-6b00-4941-f1ab-b0c44111fc80"
      },
      "source": [
        "results = model.evaluate(test_set)\n",
        "print(\"test set resulat is\",results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - 422s 19s/step - loss: 0.2782 - accuracy: 0.9299\n",
            "test set resulat is [0.27924479126930237, 0.9298718070983887]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}